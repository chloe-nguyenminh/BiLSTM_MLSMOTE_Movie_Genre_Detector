{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloe-nguyenminh/Movie_Genre_Detector_Project/blob/main/Copy_of_Movie_Detector_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf8pl6Jvc3qA"
      },
      "outputs": [],
      "source": [
        "# Movie Detector Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlamqI-Xc86c"
      },
      "outputs": [],
      "source": [
        "# Set up: Importing numpy, pandas, etc.\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from numpy.random import RandomState\n",
        "from tensorflow.keras import datasets, layers, models, Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nl8Z-jCrGsVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# READ DATA\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/n-d-d/LearnAI-Repo/main/cleaned_data_3.csv\")"
      ],
      "metadata": {
        "id": "D6Luui2KGvF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "genre_set = set()\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  lst = re.findall(r'\\w+', data.Genre[i])\n",
        "  data['Genre'][i] = lst\n",
        "  for n in range(len(lst)):\n",
        "    genre_set.add(lst[n])\n",
        "\n",
        "data1 = data[[\"imdbId\", \"Genre\", \"Poster\"]]\n",
        "print('genre_set: ', genre_set)\n",
        "print(data1)"
      ],
      "metadata": {
        "id": "0t13XfUPGvIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for genre in genre_set:\n",
        "  data1[genre] = 0\n",
        "  for i in range(len(data1)):\n",
        "    if genre in data1.iloc[i]['Genre']:\n",
        "      data1.loc[i, genre] = 1\n",
        "\n",
        "print(data1)"
      ],
      "metadata": {
        "id": "9JQsQ5CtHIV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Webscrape images from movie posters link"
      ],
      "metadata": {
        "id": "wunm9DO9HIYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "id": "cLNC19CyHPle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium"
      ],
      "metadata": {
        "id": "lDJBXztjHPn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "import requests\n",
        "import io\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "gG0XY9i2HPrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image(download_path, url, ID):\n",
        "  try: \n",
        "    image_content = requests.get(url, stream=True).content\n",
        "    image_file = io.BytesIO(image_content)\n",
        "    image = Image.open(image_file)\n",
        "    file_path = download_path + str(ID) + '.jpg'\n",
        "\n",
        "    with open(file_path, 'wb') as f:\n",
        "      image.save(f, \"JPEG\")\n",
        "  except Exception as e:\n",
        "    print('Error', e)"
      ],
      "metadata": {
        "id": "k6oyA94VHIau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, len(data1)):\n",
        "   ID = data1['imdbId'][i]\n",
        "   url = data1['Poster'][i]\n",
        "   download_image(output_path1, url, ID)"
      ],
      "metadata": {
        "id": "FGBQBEThHIeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add images in data to folders of respective categories\n",
        "# One image may belong to multiple genres"
      ],
      "metadata": {
        "id": "tcLzJLAFHqrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python imutils scikit-learn keras tensorflow"
      ],
      "metadata": {
        "id": "XHCcAdlmHqtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/data_no_dupl_with_exist"
      ],
      "metadata": {
        "id": "1t2JKtvUHqwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# source directory with all imgs\n",
        "src_dir = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/Posters_from_data3/'\n",
        "\n",
        "# destination directories\n",
        "train_dir = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/train/'\n",
        "test_dir = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/test/'\n",
        "\n",
        "test_percent = 0.2\n",
        "\n",
        "# loop through all the images in the source directory\n",
        "for filename in os.listdir(src_dir):\n",
        "    if filename.endswith('.jpg'):\n",
        "        movie_imdb_id = filename.split('/')[-1].replace('.jpg', '')\n",
        "        print(movie_imdb_id)\n",
        "        dataframe_row_index = df[df['imdbId'] == int(movie_imdb_id)].index.tolist()[0]\n",
        "        dataframe_row = df.iloc[dataframe_row_index]\n",
        "        for genre in genre_set.keys():\n",
        "          print('test', dataframe_row[genre])\n",
        "          if df.loc[dataframe_row_index][genre] == 1:\n",
        "              # move the image to the train or test directory\n",
        "              if np.random.uniform(0, 1) <= test_percent:\n",
        "                  shutil.copy(os.path.join(src_dir, filename), os.path.join(test_dir, genre))\n",
        "              else:\n",
        "                  shutil.copy(os.path.join(src_dir, filename), os.path.join(train_dir, genre))\n"
      ],
      "metadata": {
        "id": "ZoOH8PkbIC7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data after processing\n",
        "df = pd.read_csv('/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/data_no_dupl_with_existing_posters.csv')"
      ],
      "metadata": {
        "id": "u92b6rTPGvLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvnge5DjdHKp"
      },
      "outputs": [],
      "source": [
        "# resizing\n",
        "img_width = 253\n",
        "img_height = 253\n",
        "\n",
        "image_dir = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/train'\n",
        "image_dir2 = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/test'\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=image_dir,\n",
        "    image_size=(img_width, img_height),\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=image_dir2,\n",
        "    image_size=(img_width, img_height),\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "print(train_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.class_names"
      ],
      "metadata": {
        "id": "KhKFpirwDwzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "JfhJAYN5DtdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Added layer of augmentation\n",
        "data_augmentation = tf.keras.Sequential([layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)), \n",
        "                                      layers.RandomRotation(0.1), layers.RandomZoom(0.1)])"
      ],
      "metadata": {
        "id": "1_mrkJwmMmBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  batch_size=32,\n",
        "  epochs=epochs,\n",
        "  validation_data=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "fbsbXdnCMhFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp24Pz/XWFMfTNVv8I1UyY",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
